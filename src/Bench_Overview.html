<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>Progress Sonic Test Harness.</title>
</head>
<body>
Open source performance test driver.<br>
<table id="AutoNumber1" style="border-collapse: collapse; width: 807px; height: 136px;" border="0" bordercolor="#111111" cellpadding="0" cellspacing="0">
  <tbody>
    <tr>
      <td style="width: 177px;"> <a href="http://www.progress.com/" target="ProgressInc"><img style="border: 0px solid ; width: 186px; height: 64px;" src="images/Progress_RGB.jpg" alt="Progress Software Corp."></a></td>
      <td style="width: 55px;"> &nbsp;</td>
      <td style="width: 467px;"> <i>Copyright (c) 2004-2011, Progress Software Corporation - All Rights Reserved</i>.
  
      <p>Please see important <a href="#LicenseInfo">License Information</a> regarding this material. </p>
      </td>
    </tr>
  </tbody>
</table>
<p>The Performance Bench is a Java class library designed to support simple,
flexible load tests for SQL-based integration products.&nbsp; It is
tested with MySQL, but should be compliant with any JDBC
standard library. The package, including documentation and source code,
is available without charge on an open source basis.</p>
<h3>Table of Contents</h3>
<div style="margin-left: 40px;"><a href="#Package_Contents">Contents of the Bench Package</a><br>
<a href="#Getting_started:">Getting Started</a><br>
<div style="margin-left: 40px;"><a href="#Basic_installation_instructions_">Basic installation instructions</a><br>
<a href="#Invoking_the_TestHarness">Invoking the TestHarness</a><br>
<a href="#Using_the_Test_Harness_">Using the Test Harness</a><br>
</div>
<a href="#Running_tests">RunningTests</a><br>
<div style="margin-left: 40px;"><a href="#Test_Parameters">Test Parameters</a><br>
<a href="#Test_Intervals">Test Intervals</a><br>
<a href="#Measurements">Measurements</a><br>
<a href="#Multi-host_tests">Multi-host tests</a><br>
<a href="#Saving_measurements_to_a_file">Saving measurements to a file</a><br>
</div>
<a href="#LicenseInfo">License Information</a><br>
</div>
<p><span style="font-weight: bold;">Documentation for individual Java Packages:<br>
</span></p>
<div style="margin-left: 40px;">
<p><a href="com/progress/perf/gen/package.html">The Message Generator Utility</a><br>
</p>
<p><a href="com/progress/perf/harness/package.html">The Sonic Test Harness</a><br>
</p>
<p><a href="com/progress/perf/tbx/package.html">The Sonic Performance Toolbox</a><br>
</p>
</div>
<h2><a name="Package_Contents"></a>Package Contents<br>
</h2>
<p>The Sonic Test Harness contains source, binaries and examples for several Java packages:</p>
<ul>
  <li>TestHarness: the primary driver program, contains a main() method
  with full help and interactive configuration;&nbsp;launches the test DriverObj.</li>
  <li>The <i>com.progress.perf.harness</i> package contains the
implementation classes for the test harness:
    <ul>
      <li>Driver:&nbsp; controls the JMS connection pool and spawns Producers or Consumers.</li>
      <li>ProducerObj: controls test threads for JMS Producers (i.e. Publishers or Senders)</li>
      <li>ConsumerObj: controls test threads for JMS Consumers (i.e. Subscribers or Receivers)</li>
      <li>TestParams: utility class that controls input, parsing and validation of configuration parameters</li>
      <li>IntervalTimer: utility class that controls timing of test runs and gathering of results</li>
      <li>Collector: simple data collection class that tracks message throughput, latency and size statistics</li>
      <li>ConstMessageGenerator: default concrete extension of the MsgGenerator message content generator</li>
      <li>TemplateMsgGenerator: generates flexible, variable text message content</li>
      <li>ObjectMsgGenerator: creates JMS ObjectMessages based on simple or custom Java objects</li>
      <li>FileMsgGenerator: creates messages from files within a specified directory</li>
      <li>Message generator classes in the MsgGenerator: abstract class organizing various ways of generating messages</li>
    </ul>
  </li>
  <li>The <i>com.progresss.perf.gen</i> package contains implementation classes for the TemplateMsgGenerator,
to generate methodically varying text content based on an input specification template.</li>
  <li>The <i>com.progress.perf.tbx</i> package contains the Performance Toolbox Utilities, which provide general performance
measurement functions:
    <ul>
      <li>NetPing utility to measure network latency and compute correction factor for clock times</li>
      <li>DiskPerf utility to measure relative performance of disk subsystems</li>
    </ul>
  </li>
  <li>Documentation, includes this overview and API documentation</li>
  <li>Examples are provided in the <i>samples</i> subdirectory, and are explained in the Readme.txt file in that directory. </li>
</ul>
The <a href="TemplateMsgGenerator.html">TemplateMsgGenerator</a> class
provides an extension to the test harness based on the
com.progress.perf.gen
package that allows you to create powerful template files to generate
variable message content for the tests. It supports JMS message types
ByteMessage, TextMessage and the Sonic extension XMLMessage. Template
commands are XML processing instructions that allow the developer to
specify content that generates strings, values, words or dates based on
a range of statistical distribution of values.&nbsp; In addition you
can control the repetition of blocks of text or xml, and specify
parameters that are provided at runtime.
<h2><a name="Getting_started:"></a>Getting started</h2>
<h3><a name="Basic_installation_instructions_"></a>Basic installation instructions
</h3>
<ul>
  <li>Install SonicMQ version 8.x and set env variable SONICMQ_HOME to the SonicMQ directory (default is C:\sonic\MQ8.0)</li>
  <li>Unzip the test harness zip file and set env variable SONICTH_HOME to the root TestHarness directory path<br>
  </li>
  <li>Locate a Java 1.6 install, and ensure that env variable JAVA_HOME is set to it (default is C:\java\jdk1.6.0_20)</li>
  <li>Open a command window and invoke "call setenv.bat" (windows) or ".&nbsp; setenv.sh" (Unix / Bash)</li>
  <li>For non-default installation:</li>
  <ul>
    <li>All tools are portable, install locations only impact setup of PATH and CLASSPATH library paths</li>
    <li>Edit the setenv.bat (windows) or setenv.sh (unix) scripts to correct installation paths; if <br>
    </li>
    <li>Optionally, set the JAVA_HOME, SONICMQ_HOME and SONICTH_HOME to the local installs of Java/jre, SonicMQ and this Test Harness, respectively.</li>
    <li>Optionally, use any other mechanism you like to incorporate the appropriate jars in your classpath and locate the java executable.</li>
  </ul>
  <li>To rebuild Test Harness:</li>
  <ul>
    <li>You also need to install and configure <span style="font-style: italic;">ant</span>, modifying the setenv script or
setting ANT_HOME &nbsp;(requires ant v1.6 or later)</li>
    <li>Your JAVA_HOME must address a full Java jdk, not just the jre</li>
    <li>Run the command "ant all" for a full build</li>
    <li>Optionally, edit the build.xml to create tar files, include your test harness extensions, etc</li>
    <li>Optionally, use any other Java build environment you choose; the entire test harness is pure Java.<br>
    </li>
  </ul>
</ul>

<h3><a name="Invoking_the_TestHarness"></a>Invoking the TestHarness</h3>
Here are some simple tips for trying out the test harness.<br>
<ul>
  <li>Review the <a href="../README.txt">README.txt</a> file for last-minute
updates and a description of the package</li>
  <li>There are several ways to invoke TestHarness (edit the setenv.bat or setenv.sh file to correct local path variables):</li>
  <ul>
    <li>to print complete syntax information for the tool:
      <blockquote>java -cp ./lib/test_harness.jar TestHarness -help </blockquote>
    </li>
    <li>to override the default values for any specified parameters:
      <blockquote>call setenv.bat<br>java TestHarness param1=val1 param2=val2 param3=val3</blockquote>
    </li>
    <li>to override default param values using one or more Java Properties file:
      <blockquote style="margin-left: 120px;">call setenv.bat<br>
		java TestHarness -props myPropertyFile.props<br>
		java TestHarness -props baseline.props,override.props</blockquote>
    </li>
  </ul>
</ul>
<ul>
  <ul>
    <li>to prompt the user to modify each param value, then optionally save the result in a new Property file:
      <blockquote>call setenv.bat<br>
		java TestHarness -prompt </blockquote>
    </li>
    <li>You can combine the argument types. For example, you can run publishers and subscribers in different windows
based on a saved Property file with the commands:</li>
    <blockquote><code>java TestHarness -props test.props mode=pub<br>
		java TestHarness -props test.props mode=sub</code></blockquote>
  </ul>
  <li>With the -prompt option you will be prompted for each individual property. At the prompt, you have the following options:
    <blockquote>Specify client mode (PUBlisher, SUBscriber, SENDer or RECeiver)<br>
		"?" - see a detailed description of the property<br>
		"X" - change the value of the property <br>
		"D" - revert to the default value for the property<br>
		"B" - go Back to the previous param<br>
		"Q" - quit entering params and continue test harness </blockquote>
    <p>Once the prompt sequence ends, you have the option of saving settings to a
properties file.&nbsp; It may be worth going through the detailed help for each item once, to
help you understand the options available. You can abort the test harness run at any time by simply hitting the &lt;ctl-c&gt; key; the
only potential side effect of this is if test warmup or iteration runs have already started, in which case queues and durable subscribers may
not be properly cleaned up.</p>
  </li>
</ul>

<h3><a name="Using_the_Test_Harness_"></a>Using the Test Harness</h3>
<p>Once the program is set up, you can</p>
<ul>
  <li>Review the examples in the samples subdirectory:</li>
</ul>
<blockquote>
  <ul>
    <li>props - example TestHarness properties files</li>
    <li>scripts - simple shell scripts invoking TestHarness</li>
    <li>templates - examples of processing instructions used by the text generator package and TemplateMsgGenerator</li>
  </ul>
</blockquote>
<ul>
  <li>Note that a message broker connection must be set up. TestHarness will do this by:</li>
</ul>
<blockquote>
  <ul>
    <li>First, using the <i>jndiURL</i> property to establish a connection to a JNDI service; this atttempt is skipped if
you set "jndiurl=none"<br>
    </li>
    <ul>
      <li>This performs a JNDI lookup for the JMSConnectionFactory object identified by the <i>factoryName</i>
property (default factory name is "TestHarnessFactory")</li>
      <li>Authentication is performed using the <span style="font-style: italic;">user</span> and <span style="font-style: italic;">password</span> parameters<br>
      </li>
      <li>Any parameters beginning with the prefix <span style="font-style: italic;">"jndi.</span>" are added to the JNDI
		properties for the call after stripping the prefix; for example test harness parameter <span style="font-style: italic;">jndi.com.sonicsw.jndi.mfcontext.domain</span>
		is passed to the lookup as JNDI property <span style="font-style: italic;">com.sonicsw.jndi.mfcontext.domain</span><br style="font-style: italic;">
      </li>
    </ul>
    <li>If the JNDI lookup fails or is skipped, the ClientObj looks for
		a registered vendor extension, configured via the <i>vendorext</i> parameter; if one is
found, the getConnectionFactory() method for that extension plugin is invoked to create the factory.<br>
    </li>
    <ul>
      <li>The provided Sonic extension attempts to connect directly to a Sonic broker identified by parameter "sonic.url"
(default value "tcp://localhost:2506")</li>
      <li>Note that a vendor extension may override an existing parameter's characteristics or define new parameters, which typically
are prefixed with the vendor name.<br>
      </li>
    </ul>
    <li><span style="font-style: italic;">IT IS STRONGLY RECOMMENDED THAT YOU USE A NAMED JNDI CONNECTION:</span></li>
    <ul>
      <li>It will better document the use and function of the connection (e.g. if you use JNDI factory names like
"ClusteredFTConnection")</li>
      <li>It&nbsp; will make scripts more uniform and portable</li>
    </ul>
  </ul>
</blockquote>
<h2><a name="Running_tests"></a>Running tests</h2>
<p>The key to running a successful load test is to carefully analyze the questions you need answered, then tailor your use
of the Sonic TestHarness to address these questions directly.&nbsp; For tests of a JMS messaging infrastructure, you should identify the
numbers of connections, producers and consumers, along with basic information about message size and send rate, then set up properties
files for each invocation of the test harness. You can run the various invocations in different windows, taking care to start consumers first
(to avoid lost messages) and to initiate test measurement in all windows as quickly as possible. For ESB tests, the content of the
message can be critical to performing a realistic simulation, particularly if content-based routing and transformation are key
elements of the test. You may find value in using the Sonic text generation utility to methodically vary message content, so that the
various routings and transformations are appropriately exercised.<br>
</p>
<p>Each test harness client will output the message rate being achieved at the end of each test iteration, so you can verify that uniform,
steady-state performance is being achieved.&nbsp; At the end, the program will print out:<br>
</p>
<ul>
  <li>Overall throughput achieved (messages per second)</li>
  <li>Number of message processed</li>
  <li>Latency stats, if <span style="font-style: italic;">checklatency</span> is set true (average, minimum and maximum milliseconds)</li>
  <li>Message size stats, if <span style="font-style: italic;">checkmsgsize</span> is set true (average, minimum and maximum bytes)</li>
  <li>Counts of messages processed in warmup and warmdown iterations (to provide an accurate total number of messages)<br></li>
</ul>
<p>Note that you can also append these statistics to a file (<a href="#Saving_measurements_to_a_file">see below</a>).<br>
</p>
<h3><a name="Test_Parameters"></a>Test Parameters</h3>
<p>The behavior of a given TestHarness invocation depends broadly upon the values of individual test parameters.&nbsp; These include JMS behaviors, test run management and
custom parameters used for customized code or reports. Parameters are stored and managed within a singleton instance of the TestParams class,
which uses the nested TestParam class to manage individual paramater values. By default, the TestParams class uses a static initializer to
set up a parameter table with the following categories:<br>
</p>
<h4>Mode</h4>
<p>A given test client instance can run in only one domain (pubsub or point to point) and one role (producer or
consumer).&nbsp; Thus you declare the purpose of the test instance by setting mode equal to <i>pub</i>
(publisher), <i>sub</i> (subscriber), <i>send</i> (queue sender),or <i>rec</i> (queue receiver).&nbsp; To get mixed environments, you normally set up
multiple windows, each with a distinct role. </p>
<h4>Connection/Session info</h4>
<p>This covers the definition of the JMS connections and sessions, which in turn determines the topology of the
test. The number of threads launched by the test instance is equal to the number of <i>session</i>s
declared here. If <i>istransacted</i> is set true, then transacted sessions will be used, with message commit
performed at the appropriate point, indicated by the <i>msgpertxn</i>param. The <i>numdests</i> param defines the number
of queues or topics, which are named by merging a unique destination number (ranging from 1 to <i>numdests</i>)
into the destination name defined by <i>destname</i>.&nbsp;
If the <i>destname</i> includes the "@" character, the destination number will be substituted for this
character, otherwise the number is appended to the <i>destname</i> string.<br>
</p>
<h4>Producer options</h4>
<p>These parameters define the characteristics of the JMS Producer object (i.e. the publisher or
sender, depending on <i>mode</i>).&nbsp; You set message Quality of Service using the <i>deliverymode</i> and <i>priority</i>
parameters.&nbsp; <br>
</p>
<p>For more sophisticated tests, you can set the <i>isreplyto</i> param to 'true'. In this case, test harness will set the JMSReplyTo message
field to the specified destination and wait for a reply to come back.&nbsp; Make certain that there is an active JMS client out there (which can be
simulated by a test harness consumer with the "isforward" parameter set), otherwise the producer thread will wait for timeout after
each message. If the message times out, it will print a '.' to the console and continue.&nbsp; If you set <i>isreplyto</i>
and <i>checklatency</i> both true, the response time for the send/reply roundtrip will be reported.<br>
</p>
<p>Note that internal consumer used to receive the reply message will use all the consumer parameters specified for the test, including the <i>ackmode</i> and <i>msgselector</i>
parameters.&nbsp; By default, the replyTo destination (the <i>replytodest</i> parameter)&nbsp; is set to "TempDest", which results in each session
thread creating a temporary topic or queue for returned replies.&nbsp; If you use any other string, it will listen for replies on a permanent
topic or queue.&nbsp; If the <i>replytodest</i> contains the '@' symbol in the string, the '@' will be replaced with
the current Thread ID.&nbsp; This allows each thread to listen on a different permanent destination for replies.&nbsp; If you specify a <i>msgselector</i>,
the same replacement of '@' with thread ID occurs, allowing you to have all threads listen
on the same queue, but use message selectors to split the replies. </p>
<h4>Message generation options</h4>
<p>For SOA tests it can be important to introduce variation in the type and content of messages being sent.&nbsp; The <i>msgtype</i>
parameter allows you to select most of the JMS and Sonic-specific message types.&nbsp; You manipulate content by specifying a
MessageGenerator implementation, either one of the built-in options or a custom one of your own, using the <i>msggenclass</i>
parameter.&nbsp; You then set other message gen parameters to constrain the behavior. The <i>ConstantMsgGenerator</i>
simply creates a fixed message of the configured type and size and resends it multiple times. The <i>FileMsgGenerator</i>
uses the configured <i>msgfiledir</i> filesystem directory to input message data from flat files. The <i>ObjectMsgGenerator</i>
serializes objects of class <i>objectmsgclass</i> into Object messages (optionally initializing the object with current
message number).&nbsp; Finally, the <i>TemplateMsgGenerator</i> option generates unique content for each message based on an input
template file indicated by the <i>template</i> param. More details of the template message generator can be found in
the description of the <a href="com/progress/perf/gen/package-summary.html">com.progress.perf.gen package</a>.<br>
</p>
<p>Message generators also know how to generate message properties.&nbsp; These are passed as properties files back to TestHarness, where they are applied to
individual messages.&nbsp; The message generator is passed the destination ID and the test iteration number (within thread) and these
can be encoded in message property values.&nbsp; For instance, the default implementation creates message properties from the <i>msgproperties</i>
parameter and then substitutes the destination ID for every occurance of the "@" character, and the iteration number for every occurance of the "#"
character.&nbsp; This lets you randomize message property content somewhat.<br>
</p>
<p>Since message generation can be expensive in certain cases, you
might want to minimize that overhead.&nbsp; Do this by setting the <span style="font-style: italic;">msgcache</span> parameter to the number of
unique messages you want cached and sent.&nbsp; Each producer will resend this set in round-robin fashion.<br>
</p>
<h4>Consumer options</h4>
<p>For consumers, you specify the Quality of Service using the <i>durable</i> and <i>ackmode</i> parameters, and you
can optionally configure a JMS Message Selector by specifying a <i>msgselector</i> parameter string. <i>Please note: If you do not want to use a
message selector, you must leave the msgselector param at the default value of 'none'</i>.&nbsp; Also, note that if the message selector
contains the "@" sign anywhere, every instance of "@" will be replaced with the numeric thread ID.&nbsp; This allows you to set up message
selectors so that different consumer threads listen on different selectors.<br>
</p>
<p>For more sophisticated tests, you can specify that the incoming message be forwarded on to another destination, be setting the <i>isforward</i>
parameter to 'true'.&nbsp;&nbsp; In this case, all the Producer options, described above, now apply to the message that gets forwarded, including the
message generation specs.&nbsp; You can set <i>forwarddest</i> to a topic or queue name, or alternatively to 'UseReplyTo' in which case the new message
will be sent back to the JMSReplyTo destination. Note that the built-in Producer sending the reply will ignore the "isreplyto" parameter, i.e.
it will never expect a reply back from the reply message itself.<br>
</p>
<p>You can also capture a data set from the initial messages of a run, by setting the <span style="font-style: italic;">recordercount</span>
parameter to the number of messages you want to capture, and the <span style="font-style: italic;">recorderdir</span> param to the filesystem
location where you want the content dropped.&nbsp; This same directory can then be passed in to the FileMsgGenerator in subsequent test runs.<br>
</p>
<h4>Test timing and measurement</h4>
<p>This includes parameters that impact test logistics and reporting.&nbsp; One important factor for constant-load
tests is the <i>sleepmsecs</i> param, which specifies the time each thread should sleep between
messages.&nbsp; You can use this to gain general control over the rate of message production or consumption, to better simulate the actual
real-world load.&nbsp; You can also set the number and length for test intervals, and whether each test thread should immediate go into
'warmup' iterations upon launch, or alternatively to wait for the user to hit the 'enter' key before processing any messages.&nbsp; In either
event, only those messages processed after you hit the 'enter' key to begin will be included in results.&nbsp; If you <i>checklatency</i> to
'true', the end-to-end and/or round-trip latency will be measured (exactly what depends on whether you are using the replyto and forward
options).&nbsp; Note that if you are checking latency and test harness is running on multiple hosts, you must specify a <i>clockhost</i>
computer, and on that computer you must launch the NetPing program, which will correct for flaws in clock synchronization.&nbsp; If you are 
running a non-constant message generator, you can ask test harness to track message size with the <i>checkmsgsize</i> param.&nbsp;
Finally, if you specify a <i>resultsfile</i> file location, output from your test will be concatenated into that
file for aggregate analysis. This output will include the values for throughput, optionally for latency and/or message size if tracked, and
for any other parameter you specify in the <i>variablelist</i> parameter (including any custom properties). Thus you can append concurrent 
and sequential tests and use the variable list to uniquely identify each client and iteration. Then you can import the whole thing into excel for analysis.
</p>
<h4>Connection and user specs</h4>
<p>This category defines how test harness will connect to the broker. You can specify a generic JNDI lookup,
which will allow you to run multi-vendor JMS tests, or you can enter
Sonic-specific broker connect URLs.&nbsp;&nbsp; While test harness was
designed to test against any JMS provider, specific connection options
are only defined for Sonic.<br>
</p>
<h4>Additional properties not used by TestHarness</h4>
<p>This includes any custom properties that you have added to the list.&nbsp; Custom properties can be referenced
in the <i>variablelist </i>report list, or used in custom message generators and other test harness
extensions.&nbsp; You can define custom properties by simply including them on the command line (e.g. java TestHarness hostname=godzilla),
putting them in an input properties file (using java TestHarness -props file) or extending the source code.<br>
</p>
<h3><a name="Test_Intervals"></a>Test Intervals</h3>
<p>Messaging tests are often focused on measuring the <i>steady state</i> performance as high volumes of realtime messages are
processed. To avoid artifacts resulting from the startup and initialization of the various clients and services, the test harness by
default sets the <i>doWarmup</i> parameter to true, which means that test threads will start handling messages immediately upon launch,
allowing the system to come up to speed. During the warmup interval, each producer will sleep for ProducerObj.STARTUP_SLEEP_MSECS after each
send, preventing producers in warmup mode from overwhelming the system with incoming messages during this stage. Once the user hits the <i>Enter</i>
key to begin test iterations, test harness begins measuring message throughput, latency and size, as specified. After each send or receive,
Producers or Consumers will sleep as specified by the <i>sleepMsecs </i>parameter, prior to continuing.</p>
<p>Once the last interval is complete, the test harness signals all the session threads to cease measuring statistics,
then pauses a little while (about 1/5 of the test interval time) to allow them to process the signal. Then it waits for processes to
complete work, allowing subscribers additional time to deplete queues and durable subscriptions. These warmdown messages are not counted in
the message statistics, but are included in the total message count.&nbsp; Thus, regardless of warmup and warmdown behavior, assuming
you start Consumers before Producers, the total message count for Producers and Consumers should tally correctly.</p>
<p>In order to get meaningful, repeatable test results, you should check that queues and durable subscriptions are
cleared prior to the test and launch consumers prior to producers. This will avoid having the broker go into inefficient log operations and ensure that total
message counts add up. Note that test harness attempts to consume undelivered messages during the warmdown phase, assuming it isn't interrupted.<br>
</p>
<h3><a name="Measurements"></a>Measurements</h3>
<p>For each interval, TestHarness will print the throughput, in messages per second, and the message count for that
interval.&nbsp; At the end of the test run, it will print the overall throughput and message count across all intervals, and the total
message count for the run, including warmup and warmdown intervals.&nbsp; This latter is important, as it is the only way to
verify that all messages sent by producers were, in fact, received by consumers.</p>
<p>&nbsp;Message latency will be measured within consumers if you set the <i>checklatency </i>test param 'true'. If
you set <i>isreplyto </i> true, the producer will report the round-trip latency for the
request/reply loop. For end-to-end tests, where producer and consumer are in different processes, the producer stores a timestamp as a
message property, and the consumer that retrieves the message compares this with the current system time to compute message latency.&nbsp;
This is commonly called<i> end to end latency</i>.&nbsp; At the end of the run, the average, minimum and maximum message latencies will be
reported.&nbsp; For this measure to be meaningful, either both producer and consumer must be on the same system, or you must allow test harness
to synchronize times by doing the following:</p>
<ol>
  <li>specify a reference host for clock time, using the <i> clockhost</i> parameter</li>
  <li>specify <i>checklatency </i>for<i> </i>both clients </li>
  <li>start a NetPing server on the target clockhost:&nbsp;&nbsp; <font face="Fixedsys">java NetPing server forever</font></li>
  <li>start TestHarness clients as usual, but preferably one at a time (to avoid biasing the time measurements)</li>
</ol>
<p>TestHarness will compute the time discrepancy and store a correction factor that will make timestamps comparable. Another
issue in the accuracy of latency measurement is the precision of the system clock itself.&nbsp; In the current release of TestHarness,
system time is measured with the System.currentTimeMillis() call, which on many platforms has a measurement granularity of 10 msecs or more.</p>
<p>If you set the <i>checkmsgsize</i> test param 'true', TestHarness will also try to measure message size. This too is
measured at the receiving end (either replyto point or consumer), and may not precisely match the requested message size set by the <i>msgsizekb</i>
param in the producer. The actual api used to measure message size varies with message type, and is defined in the
ConsumerObj.getMessageSize() method. At the end of the run the consumer's TestHarness program will print the average, minimum and
maximum message size encountered.</p>
<h3><a name="Multi-host_tests"></a>Multi-host tests</h3>
<p>The core TestHarness program was designed to have a simple, extensible code base. As a result, it lacks the sophisticated
multi-host coordination features of SLAMD, Grinder, JUnit and other open source utilities.
As a simple alternative, we suggest opening a window for each TestHarness to be launched, using Telnet, pcAnywhere or VNC for remote
hosts. Invoke the test harness with appropriate properties files and/or param args in each window.<br>
</p>
<p>For simple tests, leave the <span style="font-style: italic;">starter</span> param at the default value of 'prompt'. Once consumer windows display
the "Press Enter key to start test intervals" message, hit &lt;return&gt; in all consumer windows, then immediately in the producer windows. We
recommend setting the <i>dowarmup</i> param 'true' (the default), toensure reasonably accurate
measurements of 'steady state' message throughput for the multihost test.</p>
<p>If you have many windows and want a more precise triggering of startup, set the <span style="font-style: italic;">start</span>
param to 'topic'; then you can synchronize the start of iterations across all clients by simply publishing a message to the 'TestHarness.start'
topic on the same message broker used for the test. In this mode all test harness clients are waiting on a topic
receive for that message, so the degree of synchronization depends on the efficiency of the pub sub mechanism of the broker. The content of
the trigger message is irrelevant and you can&nbsp;use the Sonic JMS Test Client or similar tool to perform the send. &nbsp;Since no screen input
is required, this is also the preferred way of starting test harness clients that have been launched as background processes.<br>
</p>
<h3><a name="Saving_measurements_to_a_file"></a>Saving measurements to a file</h3>
<p>You can simply pipe the output of the TestHarness program to a file, and this is adequate for many needs, or you can
instrument your test to append results to a comma-separated output file. This, in turn, is easily imported into a commercial spreadsheet
for analysis purposes. To achieve this, simply:</p>
<ol>
  <li>Specify the <i>resultsfile</i> param to indicate the output file; this can be on a shared location so
distributed clients can all merge into one file</li>
  <li>Specify in the <i>variablelist</i> param those TestHarness params whose values you want saved as <i>independent variables</i></li>
  <li>If the file does not exist, it will be created and an appropriate comma-separated header line entered at the front<br>
  </li>
  <li>Subsequent TestHarness clients will append to the file, giving you a set of individual test records</li>
  <li>Each line will include all the independent variables defined in the <i>variablelist</i> param, plus all dependent
variables (throughput, latency and message size)</li>
  <li>To help interpret the test results we highly recommend that you also invent user parameters that identify the test scenario and
run;&nbsp; for example, you could add the string "testrun=baseline,testitr=4,broker=non-ft" to the properties list, and
those values could then be included in the <span style="font-style: italic;">variablelist</span> param so they would be
written to output.</li>
  <li>If the <i>resultsfile</i> param is set to the default value 'none', only screen output is written</li>
</ol>
<h2><a name="LicenseInfo"></a>License Information</h2>
The source code and documentation of the Progress Sonic Test Harness is covered by the licensing terms defined in the <a href="../license_info.txt">license_info.txt</a>
document, included in the download package.<br>
<br>
</body>
</html>
